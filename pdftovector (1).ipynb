{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12608662,"sourceType":"datasetVersion","datasetId":7869888}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 1. Install dependencies (Run once)\n# !pip install --upgrade pip --quiet\n# !pip install \"mineru[core]\" huggingface_hub sentence-transformers chromadb pdf2image PyMuPDF --quiet\n\n# 2. Imports\nimport os\nimport re\nimport json\nimport time\nfrom requests.exceptions import ConnectionError, HTTPError\nfrom huggingface_hub import snapshot_download\nfrom sentence_transformers import SentenceTransformer\nimport chromadb\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport io\n\n# 3. Download PDF-Extract-Kit-1.0 model weights with retry/backoff\nweights_dir = \"/kaggle/working/pdf_extract_kit_models\"\nos.makedirs(weights_dir, exist_ok=True)\n\ndef download_with_retry(repo_id, local_dir, repo_type=\"model\",\n                        max_workers=1, resume_download=True,\n                        retries=5, backoff_factor=1.0):\n    for attempt in range(1, retries + 1):\n        try:\n            print(f\"[DEBUG] Attempt {attempt}/{retries}: downloading {repo_id}…\")\n            path = snapshot_download(\n                repo_id=repo_id,\n                local_dir=local_dir,\n                repo_type=repo_type,\n                max_workers=max_workers,\n                resume_download=resume_download\n            )\n            print(f\"[DEBUG] Download succeeded: {path}\")\n            return path\n        except (ConnectionError, HTTPError) as e:\n            wait = backoff_factor * (2 ** (attempt - 1))\n            print(f\"[DEBUG] Error on attempt {attempt}: {e}. Retrying in {wait:.1f}s…\")\n            time.sleep(wait)\n    raise RuntimeError(f\"[ERROR] Failed to download {repo_id} after {retries} attempts\")\n\n# snapshot_path = download_with_retry(\n#     repo_id=\"opendatalab/pdf-extract-kit-1.0\",\n#     local_dir=weights_dir\n# )\n\n# 4. Configure MinerU for local inference\nconfig = {\n    \"weights_path\": weights_dir,\n    \"device-mode\": \"cuda\",        # or \"cpu\"\n    \"models_dir\": weights_dir,\n    \"models-dir\": weights_dir,\n    # \"device-mode\": \"cuda\",         # or \"cpu\"\n    \"virtual-vram-size\": 8,\n    \"method\": \"auto\",\n    \"backend\": \"pipeline\",\n    \"formula-enable\": True,\n    \"table-enable\": True,\n    \"start-page\": 0,\n    \"end-page\": None\n}\nconf_path = \"/kaggle/working/magic-pdf.json\"\nwith open(conf_path, \"w\") as f:\n    json.dump(config, f, indent=2)\n!cp /kaggle/working/magic-pdf.json /root/magic-pdf.json\nprint(f\"[DEBUG] MinerU config written to {conf_path}\")\n\n# 5. Set PDF and output paths\npdf_path   = \"/kaggle/input/test12/rondo_pro_manual_2015.pdf\"  # update if needed\noutput_base = \"/kaggle/working/mineru_output\"\nos.makedirs(output_base, exist_ok=True)\nprint(f\"[DEBUG] PDF input: {pdf_path}\")\nprint(f\"[DEBUG] Output base directory: {output_base}\")\n\n# 6. Parse PDF with MinerU CLI (fully local inference)\nprint(\"[DEBUG] Running MinerU CLI for PDF parsing…\")\n!mineru -p {pdf_path} -o {output_base} -m auto","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nimport os\nimport string\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport fitz  # PyMuPDF\nfrom sentence_transformers import SentenceTransformer\nimport chromadb\n\n# --- Setup base paths and files ---\nbase_out = \"/kaggle/working/mineru_output\"  # Your base directory\n\n# 1. Find project folder with \"auto\" directory\nprojects = [\n    d for d in os.listdir(base_out)\n    if os.path.isdir(os.path.join(base_out, d, \"auto\"))\n]\nif not projects:\n    raise FileNotFoundError(f\"No run folder with 'auto' in {base_out}\")\n\nrun_dir = os.path.join(base_out, projects[0], \"auto\")\n\nprint(run_dir)\n# 2. Find Markdown files in run_dir\nmd_files = [f for f in os.listdir(run_dir) if f.lower().endswith(\".md\")]\nif not md_files:\n    raise FileNotFoundError(f\"No Markdown file (*.md) found in {run_dir}\")\n\n# Optionally select the first Markdown file, or apply filtering if needed\nmd_path = os.path.join(run_dir, md_files[0])\nprint(f\"Using Markdown file: {md_path}\")\n\n# 3. Extract PDF ToC Titles (keep original)\npdf_path = \"/kaggle/input/test12/rondo_pro_manual_2015.pdf\"  # Set this appropriately!\ndoc = fitz.open(pdf_path)\ntoc = doc.get_toc()\npdf_titles = set(entry[1].strip() for entry in toc if entry[1].strip())\nprint(f\"[DEBUG] Extracted {len(pdf_titles)} PDF ToC titles for heading detection.\")\n\n# --- Normalizer for Markdown lines ---\ndef normalize_line(line):\n    # Replace tabs/newlines with space, lower-case, remove punctuation, collapse spaces, strip\n    line = re.sub(r'[\\r\\n\\t]', ' ', line)\n    line = line.lower()\n    line = line.translate(str.maketrans('', '', string.punctuation))\n    line = re.sub(r'\\s+', ' ', line)\n    return line.strip()\n\n# --- Chunk Markdown using normalized lines and PDF ToC titles ---\ndef chunk_markdown_with_pdf_titles(md_path, pdf_titles):\n    print(\"[DEBUG] Starting Markdown chunking with normalized line matching…\")\n    heading_pattern = re.compile(r\"^#+\\s*\\d+(?:\\.\\d+)*\\b\")\n    image_pattern   = re.compile(r\"!\\[\\]\\((.+?)\\)\")\n    table_inline    = re.compile(r\"(<table>.*?</table>)\", re.DOTALL)\n\n    chunks = []\n    heading = None\n    content_lines = []\n    images = []\n    tables = []\n\n    with open(md_path, \"r\", encoding=\"utf-8\") as f:\n        lines = f.readlines()\n\n    for idx, raw in enumerate(lines, start=1):\n        line = raw.rstrip(\"\\n\")\n        stripped = line.lstrip()\n        norm_line = normalize_line(line)\n        debug_tag = f\"[DEBUG][Line {idx:03d}] {repr(line)}\"\n\n        # Heading detection: regex on original, or normalized line against normalized PDF TOC titles\n        is_heading = False\n        reason = \"\"\n        if stripped.startswith(\"#\") and heading_pattern.match(stripped):\n            is_heading = True\n            reason = \"markdown numeric heading\"\n        else:\n            for title in pdf_titles:\n                if norm_line == normalize_line(title):\n                    is_heading = True\n                    reason = \"normalized PDF TOC title match\"\n                    break\n\n        if is_heading:\n            print(f\"{debug_tag} → DETECTED HEADING ({reason})\")\n            if heading is not None:\n                text = \"\".join(content_lines).strip()\n                print(\n                    f\"[DEBUG]   Saving chunk: heading={repr(heading)}, \"\n                    f\"text_len={len(text)}, images={images}, tables={len(tables)}\"\n                )\n                chunks.append({\n                    \"heading\": heading,\n                    \"text\": text,\n                    \"images\": images.copy(),\n                    \"tables\": tables.copy(),\n                })\n                print(f\"[DEBUG]   Current chunk count: {len(chunks)}\")\n            heading = line\n            content_lines.clear()\n            images.clear()\n            tables.clear()\n            print(f\"[DEBUG]   New heading set: {repr(heading)}\")\n            continue\n\n        # Image detection\n        img_match = image_pattern.search(line)\n        if img_match:\n            img_path_ref = img_match.group(1)\n            images.append(img_path_ref)\n            print(f\"{debug_tag} → IMAGE REF: {img_path_ref}\")\n            continue\n\n        # Inline table detection\n        inline_tables = table_inline.findall(line)\n        if inline_tables:\n            for tbl in inline_tables:\n                tables.append(tbl)\n                print(f\"{debug_tag} → INLINE TABLE FOUND: {tbl[:60]}...\")\n            continue\n\n        # Body text\n        content_lines.append(line + \"\\n\")\n        print(f\"{debug_tag} → BODY TEXT (len now={sum(len(l) for l in content_lines)})\")\n\n    # Save final chunk\n    if heading is not None:\n        text = \"\".join(content_lines).strip()\n        print(\n            f\"[DEBUG]   Saving FINAL chunk: heading={repr(heading)}, \"\n            f\"text_len={len(text)}, images={images}, tables={len(tables)}\"\n        )\n        chunks.append({\n            \"heading\": heading,\n            \"text\": text,\n            \"images\": images.copy(),\n            \"tables\": tables.copy(),\n        })\n        print(f\"[DEBUG]   Final chunk count: {len(chunks)}\")\n\n    print(f\"[DEBUG] Completed chunking: total_chunks={len(chunks)}\")\n    return chunks\n\n# --- Use the chunking function ---\nmd_chunks = chunk_markdown_with_pdf_titles(md_path, pdf_titles)\n\n# 9. List all images in run_dir/images → image_collection\nimages_dir = os.path.join(run_dir, \"images\")\nimage_files = []\nif os.path.isdir(images_dir):\n    for fn in os.listdir(images_dir):\n        if fn.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n            image_files.append(os.path.join(images_dir, fn))\n    print(f\"[DEBUG] Found {len(image_files)} image files in {images_dir}\")\n\n# 10. Initialize ChromaDB and embedding models\nchromadb_path = f\"./chroma_db_{projects[0]}\"\nclient = chromadb.PersistentClient(path=chromadb_path)\ntext_embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\nimage_embedder = SentenceTransformer(\"clip-ViT-B-32\")\nprint(f\"[DEBUG] ChromaDB initialized at {chromadb_path}\")\n\n# 11. Store Markdown-heading chunks: embed only heading and store metadata\nmd_col = client.get_or_create_collection(\"md_heading_chunks\")\nfor i, chunk in enumerate(md_chunks):\n    combined = f\"{chunk['heading']}\\n{chunk['text']}\"\n    emb = text_embedder.encode(combined).tolist()    \n    md_col.add(\n        ids=[f\"md-{i}\"],\n        embeddings=[emb],\n        metadatas=[{\n            \"heading\": chunk[\"heading\"],\n            \"images\": \";\".join(chunk[\"images\"]),\n            \"tables_count\": json.dumps(chunk[\"tables\"]),\n        }],\n        documents=[chunk[\"text\"]]\n    )\n    print(\n        f\"[DEBUG] Stored md-{i}: heading={repr(chunk['heading'])}, images={chunk['images']}, tables={len(chunk['tables'])}\"\n    )\nprint(f\"[INFO] Inserted {len(md_chunks)} markdown-heading chunks into 'md_heading_chunks'\")\n\n# 12. Store extracted image files in 'image_collection'\nimg_col = client.get_or_create_collection(\"image_collection\")\nfor i, img_path in enumerate(image_files):\n    img = Image.open(img_path).convert(\"RGB\")\n    emb = image_embedder.encode(img).tolist()\n    img_col.add(\n        ids=[f\"img-{i}\"],\n        embeddings=[emb],\n        metadatas=[{\"file_path\": img_path}],\n        documents=[f\"[IMAGE] {img_path}\"]\n    )\n    print(f\"[DEBUG] Inserted img-{i}: file_path={img_path}\")\nprint(f\"[INFO] Inserted {len(image_files)} images into 'image_collection'\")\n\n# 13. (Optional) Visualize first layout PNG if available\nlayout_pngs = [f for f in os.listdir(run_dir) if f.lower().endswith(\".png\")]\nif layout_pngs:\n    layout = Image.open(os.path.join(run_dir, layout_pngs[0]))\n    plt.figure(figsize=(8, 12))\n    plt.imshow(layout)\n    plt.axis(\"off\")\n    plt.title(f\"Layout: {layout_pngs[0]}\")\n    plt.show()\nelse:\n    print(\"[INFO] No layout PNGs found in run directory.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport re\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport chromadb\n\n# --- PARAMETERS and setup ---\nbase_out = \"/kaggle/working/mineru_output\"  # Set as appropriate\n\n# Find project folders with \"auto\" directory\nprojects = [d for d in os.listdir(base_out) if os.path.isdir(os.path.join(base_out, d, \"auto\"))]\nif not projects:\n    raise FileNotFoundError(f\"No run folder with 'auto' in {base_out}\")\n\nrun_dir = os.path.join(base_out, projects[0], \"auto\")\n\n# Initialize ChromaDB client/collection\nchromadb_path = f\"./chroma_db_{projects[0]}\"\nclient = chromadb.PersistentClient(path=chromadb_path)\nmd_col = client.get_or_create_collection(\"md_heading_chunks\")\n\n# --- USER QUERY SECTION ---\ntry:\n    user_query = input(\"Enter your question: \").strip()\nexcept EOFError:\n    user_query = \"How to correctly mount and tighten the conveyor belts?\"\n\nif not user_query:\n    raise ValueError(\"No user query entered. Please provide a question.\")\n\n# --- Semantic search for top N relevant chunks ---\nn_results = 3\nresult = md_col.query(\n    query_texts=[user_query],\n    n_results=n_results,\n    include=[\"metadatas\", \"documents\"]\n)\n\n# --- Display the top chunks ---\nfor idx, (doc, meta) in enumerate(zip(result[\"documents\"][0], result[\"metadatas\"][0]), 1):\n    print(f\"\\n[Excerpt {idx}] Heading: {meta.get('heading')}\")\n    print(doc + (\"...\" if len(doc) > 400 else \"\"))\n    imgs = [img.strip() for img in meta.get(\"images\", \"\").split(\";\") if img.strip()]\n    if imgs:\n        print(f\"Images found: {imgs}\")\n    else:\n        print(\"No images listed for this chunk.\")\n\n# --- Choose best chunk: (automated as first, or prompt user) ---\nbest_idx = 0  # Or: int(input(\"Which excerpt to use (1/2/3)? \")) - 1\nprint(\"\\n[INFO] Using Excerpt\", best_idx + 1)\nbest_doc = result[\"documents\"][0][best_idx]\nbest_meta = result[\"metadatas\"][0][best_idx]\nimgs = [img.strip() for img in best_meta.get(\"images\", \"\").split(\";\") if img.strip()]\n\n# --- Step-by-step extraction (split by numbered steps, fallback: splitlines) ---\nsteps = re.split(r'(?<=\\.|:)\\s*(?=\\d+\\.)', best_doc)  # crude split for \"1.\", \"2.\", etc.\nsteps = [s.strip() for s in steps if s.strip()]\nif len(steps) == 1:\n    steps = [s.strip() for s in best_doc.strip().split('\\n') if s.strip()]\n\nprint(\"\\nStep-by-step Instructions:\")\nfor idx, step in enumerate(steps, 1):\n    print(f\"{idx}. {step}\")\n\n# --- Display all images associated with the chunk ---\nif imgs:\n    print(\"\\nRelevant images for these instructions:\")\n    for i, img_path in enumerate(imgs, 1):\n        print(f\"Image {i}: {img_path}\")\n        # Try resolve absolute path:\n        possible_paths = [\n            img_path,\n            os.path.join(run_dir, \"images\", img_path),\n            os.path.join(run_dir, img_path)\n        ]\n        abs_img_path = next((p for p in possible_paths if os.path.exists(p)), None)\n        if abs_img_path:\n            img = Image.open(abs_img_path)\n            plt.figure(figsize=(9, 8))\n            plt.imshow(img)\n            plt.axis(\"off\")\n            plt.title(f\"Image {i}\")\n            plt.show()\n        else:\n            print(f\"Image file not found for: {img_path}\")\nelse:\n    print(\"No images for this chunk.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import chromadb\nimport json\n\n# Use the same ChromaDB path and collection name as in your pipeline\nchromadb_path = f\"./chroma_db_{projects[0]}\"\nclient = chromadb.PersistentClient(path=chromadb_path)\ncollection = client.get_or_create_collection(\"md_heading_chunks\")\n\n# Retrieve all stored chunk IDs\nchunk_ids = collection.get()['ids']\nprint(f\"Total chunks in 'md_heading_chunks': {len(chunk_ids)}\")\n\n# Display details for every chunk, or just the first N for quick inspection\nN = len(chunk_ids)  # Change to 'len(chunk_ids)' to print everything (may be large!)\nresults = collection.get(ids=chunk_ids[:N])\n\nfor idx in range(len(results['ids'])):\n    print(f\"\\n--- Chunk {idx + 1} ---\")\n    print(\"ID:\", results['ids'][idx])\n    print(\"Heading:\", results['metadatas'][idx].get('heading', ''))\n    print(\"Images:\", results['metadatas'][idx].get('images', ''))\n    print(\"Tables count:\", results['metadatas'][idx].get('tables_count', 0))\n\n    tables_meta = results['metadatas'][idx].get('tables', None)\n    tables = []\n    if tables_meta:\n        # If you stored as JSON string, decode it;\n        # if you joined as one string, you can split by `\\n\\n` or suitable delimiter\n        try:\n            tables = json.loads(tables_meta)\n        except (TypeError, json.JSONDecodeError):\n            # If already a list, or couldn't decode, handle gracefully\n            if isinstance(tables_meta, list):\n                tables = tables_meta\n            else:\n                # fallback: treat as a single string, split if needed\n                tables = [tables_meta]\n\n    if tables:\n        print(f\"Tables ({len(tables)}):\")\n        for t_idx, table in enumerate(tables, 1):\n            preview = table[:200] + (\"...\" if len(table) > 200 else \"\")\n            print(f\"  Table {t_idx}: {preview}\")\n    else:\n        print(\"No tables in this chunk.\")\n\n    # Uncomment below to preview the text as well\n    # print(\"Text preview:\\n\", results['documents'][idx][:300], \"...\" if len(results['documents'][idx]) > 300 else \"\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n# import re\n# from PIL import Image\n# import matplotlib.pyplot as plt\n# import pandas as pd\n# from IPython.display import display  # For Jupyter, use display() for DataFrames\n\n# # --- PARAMETERS and setup ---\n# base_out = \"/kaggle/working/mineru_output\"  # Adjust as needed\n# projects = [d for d in os.listdir(base_out) if os.path.isdir(os.path.join(base_out, d, \"auto\"))]\n# if not projects:\n#     raise FileNotFoundError(f\"No run folder with 'auto' in {base_out}\")\n# run_dir = os.path.join(base_out, projects[0], \"auto\")\n\n# import chromadb\n# chromadb_path = f\"./chroma_db_{projects[0]}\"\n# client = chromadb.PersistentClient(path=chromadb_path)\n# md_col = client.get_or_create_collection(\"md_heading_chunks\")\n\n# # --- Get user query ---\n# try:\n#     user_query = input(\"Enter your question: \").strip()\n# except EOFError:\n#     user_query = \"How to correctly mount and tighten the conveyor belts?\"\n# if not user_query:\n#     raise ValueError(\"No user query entered. Please provide a question.\")\n\n# # --- Semantic search for top N relevant chunks ---\n# n_results = 3\n# result = md_col.query(\n#     query_texts=[user_query],\n#     n_results=n_results,\n#     include=[\"metadatas\", \"documents\"]\n# )\n\n# # --- Display the top chunks ---\n# for idx, (doc, meta) in enumerate(zip(result[\"documents\"][0], result[\"metadatas\"][0]), 1):\n#     print(f\"\\n[Excerpt {idx}] Heading: {meta.get('heading')}\")\n#     print(doc[:400] + (\"...\" if len(doc) > 400 else \"\"))\n#     imgs = [img.strip() for img in meta.get(\"images\", \"\").split(\";\") if img.strip()]\n#     tables = meta.get(\"tables\", [])\n#     if imgs:\n#         print(f\"Images found: {imgs}\")\n#     else:\n#         print(\"No images listed for this chunk.\")\n#     print(f\"Tables count: {len(tables)}\")\n\n# # --- Choose best chunk: automated here as first, or ask user ---\n# best_idx = 0  # or int(input(\"Which excerpt to use (1/2/3)? \")) - 1\n# print(\"\\n[INFO] Using Excerpt\", best_idx + 1)\n# best_doc = result[\"documents\"][0][best_idx]\n# best_meta = result[\"metadatas\"][0][best_idx]\n# imgs = [img.strip() for img in best_meta.get(\"images\", \"\").split(\";\") if img.strip()]\n# tables = best_meta.get(\"tables\", [])\n\n# # --- Step-by-step extraction (split by numbered steps, fallback: splitlines) ---\n# steps = re.split(r'(?<=\\.|:)\\s*(?=\\d+\\.)', best_doc)  # crude split for \"1.\", \"2.\", etc.\n# if len(steps) == 1:\n#     steps = [s.strip() for s in best_doc.strip().split('\\n') if s.strip()]\n\n# print(\"\\nStep-by-step Instructions:\")\n# for idx, step in enumerate(steps, 1):\n#     print(f\"{idx}. {step}\")\n\n# # --- Display tables from metadata ---\n# if tables:\n#     print(\"\\nRelevant tables found in this chunk:\")\n#     for i, table in enumerate(tables, 1):\n#         print(f\"\\nTable {i}:\")\n#         # If table is stored as HTML string, you can print or parse it\n#         if isinstance(table, str):\n#             print(table)  # raw HTML or markdown snippet\n            \n#             # Optionally convert markdown tables to DataFrame for nicer display if you recognize markdown\n#             try:\n#                 from io import StringIO\n#                 # crude conversion for markdown tables if applicable\n#                 if table.strip().startswith(\"|\"):\n#                     csv_like = \"\\n\".join(\n#                         line.strip() for line in table.splitlines() if line.strip()\n#                     )\n#                     csv_like = re.sub(r'^\\|', '', csv_like, flags=re.MULTILINE)\n#                     csv_like = re.sub(r'\\|$', '', csv_like, flags=re.MULTILINE)\n#                     csv_like = re.sub(r'\\|', ',', csv_like)\n#                     df = pd.read_csv(StringIO(csv_like))\n#                     print(\"Rendered as DataFrame:\")\n#                     display(df)\n#             except Exception as e:\n#                 print(f\"Could not parse table to DataFrame: {e}\")\n\n#         # If table is structured data (e.g., list of rows), try render as DataFrame\n#         elif isinstance(table, (list, tuple)):\n#             try:\n#                 df = pd.DataFrame(table)\n#                 print(\"Rendered as DataFrame:\")\n#                 display(df)\n#             except Exception as e:\n#                 print(f\"Could not convert table data to DataFrame: {e}\")\n#                 print(table)\n#         else:\n#             print(table)\n# else:\n#     print(\"No tables found in this chunk.\")\n\n# # --- Display all images associated with the chunk ---\n# if imgs:\n#     print(\"\\nRelevant images for these instructions:\")\n#     for i, img_path in enumerate(imgs, 1):\n#         print(f\"Image {i}: {img_path}\")\n#         # Try resolve absolute path of the image\n#         possible_paths = [\n#             img_path,\n#             os.path.join(run_dir, \"images\", img_path),\n#             os.path.join(run_dir, img_path)\n#         ]\n#         abs_img_path = next((p for p in possible_paths if os.path.exists(p)), None)\n#         if abs_img_path:\n#             try:\n#                 img = Image.open(abs_img_path)\n#                 plt.figure(figsize=(6, 5))\n#                 plt.imshow(img)\n#                 plt.axis(\"off\")\n#                 plt.title(f\"Image {i}\")\n#                 plt.show()\n#             except Exception as e:\n#                 print(f\"Error opening image {img_path}: {e}\")\n#         else:\n#             print(f\"Image file not found for: {img_path}\")\n# else:\n#     print(\"No images for this chunk.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Retrieve all stored documents, metadatas, and ids\n# results = collection.get(include=[\"documents\", \"metadatas\"])\n\n# all_ids = results[\"ids\"]\n# all_docs = results[\"documents\"]\n# all_metas = results[\"metadatas\"]\n\n# print(f\"Total chunks stored: {len(all_ids)}\")\n\n# for idx in range(len(all_ids)):\n#     print(f\"ID: {all_ids[idx]}\")\n#     print(f\"Heading: {all_metas[idx].get('heading', '')}\")\n#     print(f\"Text excerpt: {all_docs[idx].replace(chr(10), ' ')}\")\n#     images = all_metas[idx].get(\"images\", \"\")\n#     if images:\n#         print(\"Associated images:\", images)\n#     print(\"-\" * 75)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import fitz  # PyMuPDF\n\n# # Open the PDF file\n# doc = fitz.open(pdf_path)\n\n# # Retrieve the Table of Contents (list of [level, title, page number])\n# toc = doc.get_toc()\n\n# # Extract just the titles (ensure they are exactly as in the PDF)\n# titles = [entry[1].strip() for entry in toc]\n\n# # Optional: print all titles to verify\n# for title in titles:\n#     print(title)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}